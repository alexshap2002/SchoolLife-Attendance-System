#!/usr/bin/env python3
"""
===============================================================
üìä –ú–û–ù–Ü–¢–û–†–ò–ù–ì –ë–ê–ó–ò –î–ê–ù–ò–• –¢–ê –ü–†–û–î–£–ö–¢–ò–í–ù–û–°–¢–Ü
===============================================================
üìÖ –î–∞—Ç–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è: 2025-09-15
üéØ –ú–µ—Ç–∞: –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ PostgreSQL —Ç–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
===============================================================
"""

import asyncio
import asyncpg
import json
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any
import argparse

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/db_monitoring.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DatabaseMonitor:
    """–ö–ª–∞—Å –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –±–∞–∑–∏ –¥–∞–Ω–∏—Ö."""
    
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.metrics = {}
    
    async def connect(self):
        """–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î."""
        try:
            self.conn = await asyncpg.connect(self.connection_string)
            logger.info("‚úÖ –ü—ñ–¥–∫–ª—é—á–µ–Ω–æ –¥–æ –ë–î –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É")
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î: {e}")
            raise
    
    async def disconnect(self):
        """–í—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –≤—ñ–¥ –ë–î."""
        if hasattr(self, 'conn') and self.conn:
            await self.conn.close()
            logger.info("üîå –í—ñ–¥–∫–ª—é—á–µ–Ω–æ –≤—ñ–¥ –ë–î")
    
    async def get_database_size(self) -> Dict[str, Any]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É –ë–î —Ç–∞ —Ç–∞–±–ª–∏—Ü—å."""
        try:
            # –ó–∞–≥–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –ë–î
            db_size_query = """
                SELECT pg_size_pretty(pg_database_size(current_database())) as database_size,
                       pg_database_size(current_database()) as database_size_bytes
            """
            db_size = await self.conn.fetchrow(db_size_query)
            
            # –†–æ–∑–º—ñ—Ä–∏ —Ç–∞–±–ª–∏—Ü—å
            tables_size_query = """
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes,
                    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as index_size
                FROM pg_tables 
                WHERE schemaname = 'public'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
                LIMIT 20
            """
            tables = await self.conn.fetch(tables_size_query)
            
            return {
                "database_size": db_size['database_size'],
                "database_size_bytes": db_size['database_size_bytes'],
                "tables": [dict(table) for table in tables]
            }
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É –ë–î: {e}")
            return {}
    
    async def get_connection_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω—å."""
        try:
            query = """
                SELECT 
                    count(*) as total_connections,
                    count(*) FILTER (WHERE state = 'active') as active_connections,
                    count(*) FILTER (WHERE state = 'idle') as idle_connections,
                    count(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction,
                    max(now() - query_start) as longest_query_duration,
                    max(now() - state_change) as longest_idle_duration
                FROM pg_stat_activity 
                WHERE pid != pg_backend_pid()
            """
            result = await self.conn.fetchrow(query)
            return dict(result)
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—ñ–¥–∫–ª—é—á–µ–Ω—å: {e}")
            return {}
    
    async def get_table_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–∞–±–ª–∏—Ü—å."""
        try:
            query = """
                SELECT 
                    schemaname,
                    tablename,
                    n_tup_ins as inserts,
                    n_tup_upd as updates,
                    n_tup_del as deletes,
                    n_live_tup as live_tuples,
                    n_dead_tup as dead_tuples,
                    last_vacuum,
                    last_autovacuum,
                    last_analyze,
                    last_autoanalyze
                FROM pg_stat_user_tables 
                ORDER BY n_tup_ins + n_tup_upd + n_tup_del DESC
                LIMIT 20
            """
            result = await self.conn.fetch(query)
            return {"tables": [dict(row) for row in result]}
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–∞–±–ª–∏—Ü—å: {e}")
            return {}
    
    async def get_index_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ñ–Ω–¥–µ–∫—Å—ñ–≤."""
        try:
            query = """
                SELECT 
                    schemaname,
                    tablename,
                    indexname,
                    idx_tup_read,
                    idx_tup_fetch,
                    pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
                    idx_scan as scans
                FROM pg_stat_user_indexes 
                ORDER BY idx_scan DESC
                LIMIT 20
            """
            result = await self.conn.fetch(query)
            return {"indexes": [dict(row) for row in result]}
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —ñ–Ω–¥–µ–∫—Å—ñ–≤: {e}")
            return {}
    
    async def get_slow_queries(self) -> Dict[str, Any]:
        """–ü–æ–≤—ñ–ª—å–Ω—ñ –∑–∞–ø–∏—Ç–∏."""
        try:
            query = """
                SELECT 
                    query,
                    calls,
                    total_time,
                    mean_time,
                    min_time,
                    max_time,
                    stddev_time,
                    rows
                FROM pg_stat_statements 
                WHERE query NOT LIKE '%pg_stat_statements%'
                ORDER BY mean_time DESC
                LIMIT 10
            """
            result = await self.conn.fetch(query)
            return {"slow_queries": [dict(row) for row in result]}
        except Exception as e:
            # pg_stat_statements –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
            logger.warning("‚ö†Ô∏è pg_stat_statements –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
            return {"slow_queries": []}
    
    async def get_locks(self) -> Dict[str, Any]:
        """–ü–æ—Ç–æ—á–Ω—ñ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è."""
        try:
            query = """
                SELECT 
                    pg_stat_activity.pid,
                    pg_stat_activity.usename,
                    pg_stat_activity.query,
                    pg_locks.mode,
                    pg_locks.locktype,
                    pg_locks.granted
                FROM pg_locks 
                JOIN pg_stat_activity ON pg_locks.pid = pg_stat_activity.pid
                WHERE NOT pg_locks.granted
                ORDER BY pg_stat_activity.query_start
            """
            result = await self.conn.fetch(query)
            return {"locks": [dict(row) for row in result]}
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –±–ª–æ–∫—É–≤–∞–Ω—å: {e}")
            return {}
    
    async def get_school_specific_metrics(self) -> Dict[str, Any]:
        """–°–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —à–∫–æ–ª–∏."""
        try:
            metrics = {}
            
            # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤
            counts_query = """
                SELECT 
                    (SELECT COUNT(*) FROM students) as total_students,
                    (SELECT COUNT(*) FROM teachers WHERE active = true) as active_teachers,
                    (SELECT COUNT(*) FROM clubs) as total_clubs,
                    (SELECT COUNT(*) FROM conducted_lessons) as total_lessons,
                    (SELECT COUNT(*) FROM attendance WHERE status = 'PRESENT') as total_attendances,
                    (SELECT COUNT(*) FROM lesson_events WHERE status = 'PLANNED' AND date >= CURRENT_DATE) as upcoming_lessons
            """
            counts = await self.conn.fetchrow(counts_query)
            metrics.update(dict(counts))
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ç–∏–∂–¥–µ–Ω—å
            week_stats_query = """
                SELECT 
                    COUNT(DISTINCT lesson_date) as lessons_this_week,
                    COUNT(*) as total_conducted_lessons,
                    SUM(present_students) as total_present_students,
                    AVG(present_students) as avg_students_per_lesson
                FROM conducted_lessons 
                WHERE lesson_date >= CURRENT_DATE - INTERVAL '7 days'
            """
            week_stats = await self.conn.fetchrow(week_stats_query)
            metrics.update({f"week_{k}": v for k, v in dict(week_stats).items()})
            
            # –¢–æ–ø-5 –Ω–∞–π–∞–∫—Ç–∏–≤–Ω—ñ—à–∏—Ö –≥—É—Ä—Ç–∫—ñ–≤
            top_clubs_query = """
                SELECT 
                    c.name,
                    COUNT(cl.id) as lessons_count,
                    SUM(cl.present_students) as total_students
                FROM clubs c
                LEFT JOIN conducted_lessons cl ON c.id = cl.club_id 
                    AND cl.lesson_date >= CURRENT_DATE - INTERVAL '30 days'
                GROUP BY c.id, c.name
                ORDER BY lessons_count DESC
                LIMIT 5
            """
            top_clubs = await self.conn.fetch(top_clubs_query)
            metrics["top_clubs"] = [dict(row) for row in top_clubs]
            
            return metrics
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —à–∫—ñ–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫: {e}")
            return {}
    
    async def collect_all_metrics(self) -> Dict[str, Any]:
        """–ó–±—ñ—Ä –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫."""
        logger.info("üìä –ü–æ—á–∞—Ç–æ–∫ –∑–±–æ—Ä—É –º–µ—Ç—Ä–∏–∫...")
        
        self.metrics = {
            "timestamp": datetime.now().isoformat(),
            "database_size": await self.get_database_size(),
            "connections": await self.get_connection_stats(),
            "tables": await self.get_table_stats(),
            "indexes": await self.get_index_stats(),
            "slow_queries": await self.get_slow_queries(),
            "locks": await self.get_locks(),
            "school_metrics": await self.get_school_specific_metrics()
        }
        
        logger.info("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∑—ñ–±—Ä–∞–Ω–æ")
        return self.metrics
    
    async def save_metrics(self, filepath: str):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ —É —Ñ–∞–π–ª."""
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.metrics, f, indent=2, default=str, ensure_ascii=False)
            logger.info(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filepath}")
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    def print_summary(self):
        """–í–∏–≤–µ–¥–µ–Ω–Ω—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ –º–µ—Ç—Ä–∏–∫."""
        if not self.metrics:
            logger.warning("‚ö†Ô∏è –ù–µ–º–∞—î –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
            return
        
        print("\n" + "="*60)
        print("üìä –†–ï–ó–Æ–ú–ï –ú–û–ù–Ü–¢–û–†–ò–ù–ì–£ –ë–ê–ó–ò –î–ê–ù–ò–•")
        print("="*60)
        
        # –†–æ–∑–º—ñ—Ä –ë–î
        db_size = self.metrics.get("database_size", {})
        if db_size:
            print(f"üíæ –†–æ–∑–º—ñ—Ä –ë–î: {db_size.get('database_size', 'N/A')}")
        
        # –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
        conn = self.metrics.get("connections", {})
        if conn:
            print(f"üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è: {conn.get('total_connections', 'N/A')} "
                  f"(–∞–∫—Ç–∏–≤–Ω–∏—Ö: {conn.get('active_connections', 'N/A')})")
        
        # –®–∫—ñ–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
        school = self.metrics.get("school_metrics", {})
        if school:
            print(f"üë• –°—Ç—É–¥–µ–Ω—Ç—ñ–≤: {school.get('total_students', 'N/A')}")
            print(f"üë®‚Äçüè´ –ê–∫—Ç–∏–≤–Ω–∏—Ö –≤—á–∏—Ç–µ–ª—ñ–≤: {school.get('active_teachers', 'N/A')}")
            print(f"üéØ –ì—É—Ä—Ç–∫—ñ–≤: {school.get('total_clubs', 'N/A')}")
            print(f"üìö –ü—Ä–æ–≤–µ–¥–µ–Ω–∏—Ö —É—Ä–æ–∫—ñ–≤: {school.get('total_lessons', 'N/A')}")
            print(f"üìÖ –ó–∞–ø–ª–∞–Ω–æ–≤–∞–Ω–∏—Ö —É—Ä–æ–∫—ñ–≤: {school.get('upcoming_lessons', 'N/A')}")
        
        # –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è
        locks = self.metrics.get("locks", {}).get("locks", [])
        if locks:
            print(f"üîí –ê–∫—Ç–∏–≤–Ω–∏—Ö –±–ª–æ–∫—É–≤–∞–Ω—å: {len(locks)}")
        
        print("="*60)

async def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è."""
    parser = argparse.ArgumentParser(description='–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö —à–∫–æ–ª–∏')
    parser.add_argument('--save', action='store_true', help='–ó–±–µ—Ä–µ–≥—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ —É —Ñ–∞–π–ª')
    parser.add_argument('--output', default='/app/logs/metrics_{timestamp}.json', 
                       help='–®–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫')
    parser.add_argument('--db-url', default='postgresql://postgres:postgres@db:5432/school_db',
                       help='URL –±–∞–∑–∏ –¥–∞–Ω–∏—Ö')
    
    args = parser.parse_args()
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –¥–ª—è –ª–æ–≥—ñ–≤
    os.makedirs('/app/logs', exist_ok=True)
    
    monitor = DatabaseMonitor(args.db_url)
    
    try:
        await monitor.connect()
        await monitor.collect_all_metrics()
        
        monitor.print_summary()
        
        if args.save:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = args.output.format(timestamp=timestamp)
            await monitor.save_metrics(output_file)
        
    except Exception as e:
        logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É: {e}")
        return 1
    finally:
        await monitor.disconnect()
    
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main()))
